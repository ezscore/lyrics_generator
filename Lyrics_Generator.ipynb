{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import config #api_key\n",
    "import functions\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = ['NAV', 'Future' ,'Lil Uzi Vert', 'Meek Mill', 'J. Cole', 'Chief Keef', \\\n",
    "           'Young Thug', 'Travis Scott', '21 Savage', 'Gunna' ,'Lil Baby',\\\n",
    "           'Famous Dex', 'The Weeknd' ,'Juice WRLD', 'Offset', 'Migos', 'Trippie Redd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def productionize(name):\n",
    "    song_lyrics = []\n",
    "    \n",
    "    artist = functions.request_artist(name)\n",
    "    artist_id = functions.get_artist_id(artist)\n",
    "    songs = functions.get_song_id(artist_id)\n",
    "    \n",
    "    songs = [song[\"id\"] for song in songs\n",
    "        if song[\"primary_artist\"][\"id\"] == artist_id]\n",
    "    \n",
    "    for song in songs:\n",
    "        song_lyrics.append(functions.retrieve_lyrics(song))\n",
    "    \n",
    "    print('Colleted all lyrics for {}'.format(name))\n",
    "    return functions.lyr_to_df(song_lyrics, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for NAV\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Page 45 finished scraping\n",
      "Page 46 finished scraping\n",
      "Page 47 finished scraping\n",
      "Page 48 finished scraping\n",
      "Page 49 finished scraping\n",
      "Page 50 finished scraping\n",
      "Page 51 finished scraping\n",
      "Page 52 finished scraping\n",
      "Page 53 finished scraping\n",
      "Page 54 finished scraping\n",
      "Page 55 finished scraping\n",
      "Page 56 finished scraping\n",
      "Page 57 finished scraping\n",
      "Page 58 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Future\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Lil Uzi Vert\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Meek Mill\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for J. Cole\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Page 45 finished scraping\n",
      "Page 46 finished scraping\n",
      "Page 47 finished scraping\n",
      "Page 48 finished scraping\n",
      "Page 49 finished scraping\n",
      "Page 50 finished scraping\n",
      "Page 51 finished scraping\n",
      "Page 52 finished scraping\n",
      "Page 53 finished scraping\n",
      "Page 54 finished scraping\n",
      "Page 55 finished scraping\n",
      "Page 56 finished scraping\n",
      "Page 57 finished scraping\n",
      "Page 58 finished scraping\n",
      "Page 59 finished scraping\n",
      "Page 60 finished scraping\n",
      "Page 61 finished scraping\n",
      "Page 62 finished scraping\n",
      "Page 63 finished scraping\n",
      "Page 64 finished scraping\n",
      "Page 65 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Chief Keef\n",
      "Page 2 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Young Thug\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Travis Scott\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for 21 Savage\n",
      "Page 2 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Gunna\n",
      "Page 2 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Lil Baby\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Famous Dex\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for The Weeknd\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Juice WRLD\n",
      "Page 2 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Offset\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Migos\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Collected lyrics for all songs\n",
      "Colleted all lyrics for Trippie Redd\n"
     ]
    }
   ],
   "source": [
    "for artist in artists:\n",
    "    df_lists.append(productionize(artist))\n",
    "# productionize('Travis Scott')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_df = pd.concat(df_lists, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_tuples = [tuple(x) for x in major_df.to_records(index=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(\n",
    "      host = config.my_cred['host'],\n",
    "      user = config.my_cred['user'],\n",
    "      passwd = config.my_cred['pw'],\n",
    "      database= 'genius_lyrics'\n",
    ")\n",
    "\n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(cursor, database):\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            \"CREATE DATABASE {} DEFAULT CHARACTER SET 'utf8'\".format(database))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Failed creating database: {}\".format(err))\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_database(cursor, 'genius_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE TABLE\n",
    "cursor.execute(\"\"\"USE genius_lyrics\"\"\")\n",
    "TABLES = {}\n",
    "TABLES['lyrics'] = (\n",
    "    \"CREATE TABLE lyrics (\"\n",
    "    \"  id INT NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  artist varchar(255),\"\n",
    "    \"  titles varchar(255),\"\n",
    "    \"  lyric TEXT NOT NULL,\"\n",
    "    \"  PRIMARY KEY (id)\"\n",
    "    \") ENGINE=InnoDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table lyrics: OK\n"
     ]
    }
   ],
   "source": [
    "for table_name in TABLES:\n",
    "    table_description = TABLES[table_name]\n",
    "    try:\n",
    "        print(\"Creating table {}: \".format(table_name), end='')\n",
    "        cursor.execute(table_description)\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(\"already exists.\")\n",
    "        else:\n",
    "            print(err.msg)\n",
    "    else:\n",
    "        print(\"OK\")\n",
    "\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Data Into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_insert_lyrics(cnx, cursor, lyrics):\n",
    "    stmt = (\"INSERT INTO lyrics (artist, titles, lyric) VALUES (%s,%s, %s)\")\n",
    "    cursor.executemany(stmt, lyrics)\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_insert_lyrics(cnx, cursor, lyrics_tuples)\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
